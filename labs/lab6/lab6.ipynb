{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, RFE, mutual_info_classif\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "  class                                               text\n0   ham  Go until jurong point, crazy.. Available only ...\n1   ham                      Ok lar... Joking wif u oni...\n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3   ham  U dun say so early hor... U c already then say...\n4   ham  Nah I don't think he goes to usf, he lives aro...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('SMS.tsv', sep='\\t')\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  type\n0  Go until jurong point, crazy.. Available only ...     0\n1                      Ok lar... Joking wif u oni...     0\n2  Free entry in 2 a wkly comp to win FA Cup fina...     1\n3  U dun say so early hor... U c already then say...     0\n4  Nah I don't think he goes to usf, he lives aro...     0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'] = pd.factorize(df['class'])[0]  # ham - 0, spam - 1\n",
    "df = df.drop('class', axis=1)\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "y = df['type']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "counted = CountVectorizer()\n",
    "X = counted.fit_transform(df['text'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "(5572, 8713)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['00', '000', '000pes', ..., 'èn', 'ú1', '〨ud'], dtype=object)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counted.get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "feature_names_inline = counted.get_feature_names_out()\n",
    "\n",
    "\n",
    "def print_best_features(features, values=None):\n",
    "    if values is not None:\n",
    "        for feature_num in features[:num_of_features]:\n",
    "            print(f'{feature_names_inline[feature_num]}, {feature_num}, Value: {values[feature_num]}.')\n",
    "    else:\n",
    "        for feature_num in features[:num_of_features]:\n",
    "            print(f'{feature_names_inline[feature_num]}, {feature_num}.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "num_of_features = 30"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def gen_model(model):\n",
    "    print('Встроенная')\n",
    "    model.fit(X, y)\n",
    "    values = model.feature_importances_\n",
    "    features = np.argsort(values)[::-1][:num_of_features]\n",
    "    count = 0\n",
    "    for feature_num in features[:num_of_features]:\n",
    "        print(f' Word: {feature_names_inline[feature_num]},'\n",
    "              f' Weight: {values[feature_num]}.'\n",
    "              f' Count: {count + 1}')\n",
    "        count += 1\n",
    "\n",
    "    features_2 = []\n",
    "    n = X.shape[1]\n",
    "    while len(features_2) < num_of_features:\n",
    "        print(f'Count {len(features_2) + 1}/{num_of_features} start')\n",
    "        best_feature = None\n",
    "        best_score = -1\n",
    "        for feature in range(n):\n",
    "            features_2.append(feature)\n",
    "            model.fit(X_train[:, features_2], y_train)\n",
    "            score = model.score(X_test[:, features_2], y_test)\n",
    "            if score >= best_score:\n",
    "                best_feature = feature\n",
    "                best_score = score\n",
    "            features_2.remove(feature)\n",
    "        features_2.append(best_feature)\n",
    "        print(f'Count {len(features_2)}/{num_of_features} finish Feature: {feature_names_inline[best_feature]}')\n",
    "\n",
    "    for feature_num in features_2[:num_of_features]:\n",
    "        print(f' Word: {feature_names_inline[feature_num]},'\n",
    "              f' Weight: {values[feature_num]}.'\n",
    "              f' Count: {count + 1}')\n",
    "        count += 1\n",
    "\n",
    "    X_train_filter = X_train\n",
    "    corr = X_train_filter.corr(method='pearson')\n",
    "    corr_class = corr['class']\n",
    "    coef_filt = corr_class.sort_values()\n",
    "    features_3 = np.array(coef_filt.index[-30:-1])[::-1]\n",
    "\n",
    "    for feature_num in features_3[:num_of_features]:\n",
    "        print(f' Word: {feature_names_inline[feature_num]},'\n",
    "                f' Weight: {values[feature_num]}.'\n",
    "                f' Count: {count + 1}')\n",
    "        count += 1\n",
    "    return (values, features, features_2, features_3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Встроенная\n",
      " Word: call, Weight: 0.2016224717451438. Count: 1\n",
      " Word: txt, Weight: 0.1727413859775589. Count: 2\n",
      " Word: www, Weight: 0.06789969064320896. Count: 3\n",
      " Word: me, Weight: 0.052485333879488796. Count: 4\n",
      " Word: ll, Weight: 0.0418055233322104. Count: 5\n",
      " Word: free, Weight: 0.040225369819395874. Count: 6\n",
      " Word: claim, Weight: 0.027602133812263455. Count: 7\n",
      " Word: 150p, Weight: 0.02737972476118965. Count: 8\n",
      " Word: uk, Weight: 0.019040462693204644. Count: 9\n",
      " Word: win, Weight: 0.013528227197013127. Count: 10\n",
      " Word: your, Weight: 0.012948930587105112. Count: 11\n",
      " Word: tones, Weight: 0.011824447159562502. Count: 12\n",
      " Word: my, Weight: 0.009643374592073959. Count: 13\n",
      " Word: stop, Weight: 0.009067872820020088. Count: 14\n",
      " Word: ringtone, Weight: 0.008957301899475262. Count: 15\n",
      " Word: unsubscribe, Weight: 0.008895156863552958. Count: 16\n",
      " Word: service, Weight: 0.00870107778786419. Count: 17\n",
      " Word: lt, Weight: 0.008388549237161282. Count: 18\n",
      " Word: get, Weight: 0.007773101083425215. Count: 19\n",
      " Word: ac, Weight: 0.0074463508786182415. Count: 20\n",
      " Word: freemsg, Weight: 0.007430264572983289. Count: 21\n",
      " Word: home, Weight: 0.006731315376055996. Count: 22\n",
      " Word: got, Weight: 0.00652259241865887. Count: 23\n",
      " Word: to, Weight: 0.006021960908618013. Count: 24\n",
      " Word: 10p, Weight: 0.005997079903878733. Count: 25\n",
      " Word: can, Weight: 0.005882495360819907. Count: 26\n",
      " Word: ok, Weight: 0.005776196302426399. Count: 27\n",
      " Word: pls, Weight: 0.005167183372481236. Count: 28\n",
      " Word: da, Weight: 0.004910006272808359. Count: 29\n",
      " Word: http, Weight: 0.0045105422039084745. Count: 30\n",
      "Count 1/30 start\n",
      "Count 1/30 finish Feature: txt\n",
      "Count 2/30 start\n",
      "Count 2/30 finish Feature: claim\n",
      "Count 3/30 start\n",
      "Count 3/30 finish Feature: 150p\n",
      "Count 4/30 start\n",
      "Count 4/30 finish Feature: www\n",
      "Count 5/30 start\n",
      "Count 5/30 finish Feature: mobile\n",
      "Count 6/30 start\n",
      "Count 6/30 finish Feature: service\n",
      "Count 7/30 start\n",
      "Count 7/30 finish Feature: co\n",
      "Count 8/30 start\n",
      "Count 8/30 finish Feature: urgent\n",
      "Count 9/30 start\n",
      "Count 9/30 finish Feature: ltd\n",
      "Count 10/30 start\n",
      "Count 10/30 finish Feature: ac\n",
      "Count 11/30 start\n",
      "Count 11/30 finish Feature: 800\n",
      "Count 12/30 start\n",
      "Count 12/30 finish Feature: win\n",
      "Count 13/30 start\n",
      "Count 13/30 finish Feature: we\n",
      "Count 14/30 start\n",
      "Count 14/30 finish Feature: so\n",
      "Count 15/30 start\n",
      "Count 15/30 finish Feature: gay\n",
      "Count 16/30 start\n",
      "Count 16/30 finish Feature: 60p\n",
      "Count 17/30 start\n",
      "Count 17/30 finish Feature: 500\n",
      "Count 18/30 start\n",
      "Count 18/30 finish Feature: winner\n",
      "Count 19/30 start\n",
      "Count 19/30 finish Feature: want\n",
      "Count 20/30 start\n",
      "Count 20/30 finish Feature: valid\n",
      "Count 21/30 start\n",
      "Count 21/30 finish Feature: tv\n",
      "Count 22/30 start\n",
      "Count 22/30 finish Feature: tones\n",
      "Count 23/30 start\n",
      "Count 23/30 finish Feature: suprman\n",
      "Count 24/30 start\n",
      "Count 24/30 finish Feature: sipix\n",
      "Count 25/30 start\n",
      "Count 25/30 finish Feature: sam\n",
      "Count 26/30 start\n",
      "Count 26/30 finish Feature: ringtone\n",
      "Count 27/30 start\n",
      "Count 27/30 finish Feature: networks\n",
      "Count 28/30 start\n",
      "Count 28/30 finish Feature: minmobsmorelkpobox177hp51fl\n",
      "Count 29/30 start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "values_Dec_My, features_v, features_w, features_f = gen_model(DecisionTreeClassifier())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "model = SelectKBest(score_func=chi2, k=num_of_features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'rv_continuous_frozen'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m X_train_chi2 \u001B[38;5;241m=\u001B[39m X_train\n\u001B[0;32m      2\u001B[0m select_chi2 \u001B[38;5;241m=\u001B[39m SelectKBest(chi2, k \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m30\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m \u001B[43mselect_chi2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_chi2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m features_b_chi \u001B[38;5;241m=\u001B[39m select_chi2\u001B[38;5;241m.\u001B[39mget_support(indices\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_set_output.py:140\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[1;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 140\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m f(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    141\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    142\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[0;32m    143\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m    144\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m    145\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[0;32m    146\u001B[0m         )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:881\u001B[0m, in \u001B[0;36mTransformerMixin.fit_transform\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m    878\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n\u001B[0;32m    879\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    880\u001B[0m     \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[1;32m--> 881\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_set_output.py:140\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[1;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 140\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m f(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    141\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    142\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[0;32m    143\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m    144\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m    145\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[0;32m    146\u001B[0m         )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_selection\\_base.py:90\u001B[0m, in \u001B[0;36mSelectorMixin.transform\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;66;03m# note: we use _safe_tags instead of _get_tags because this is a\u001B[39;00m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;66;03m# public Mixin.\u001B[39;00m\n\u001B[0;32m     83\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(\n\u001B[0;32m     84\u001B[0m     X,\n\u001B[0;32m     85\u001B[0m     dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     88\u001B[0m     reset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m     89\u001B[0m )\n\u001B[1;32m---> 90\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_selection\\_base.py:94\u001B[0m, in \u001B[0;36mSelectorMixin._transform\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_transform\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m     93\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Reduce X to the selected features.\"\"\"\u001B[39;00m\n\u001B[1;32m---> 94\u001B[0m     mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_support\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     95\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m mask\u001B[38;5;241m.\u001B[39many():\n\u001B[0;32m     96\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m     97\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo features were selected: either the data is\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     98\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m too noisy or the selection test too strict.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     99\u001B[0m             \u001B[38;5;167;01mUserWarning\u001B[39;00m,\n\u001B[0;32m    100\u001B[0m         )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_selection\\_base.py:53\u001B[0m, in \u001B[0;36mSelectorMixin.get_support\u001B[1;34m(self, indices)\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_support\u001B[39m(\u001B[38;5;28mself\u001B[39m, indices\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m     34\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;124;03m    Get a mask, or integer index, of the features selected.\u001B[39;00m\n\u001B[0;32m     36\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;124;03m        values are indices into the input feature vector.\u001B[39;00m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 53\u001B[0m     mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_support_mask\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m mask \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m indices \u001B[38;5;28;01melse\u001B[39;00m np\u001B[38;5;241m.\u001B[39mwhere(mask)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:685\u001B[0m, in \u001B[0;36mSelectKBest._get_support_mask\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    683\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscores_\u001B[38;5;241m.\u001B[39mshape, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mbool\u001B[39m)\n\u001B[0;32m    684\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 685\u001B[0m     scores \u001B[38;5;241m=\u001B[39m \u001B[43m_clean_nans\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscores_\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    686\u001B[0m     mask \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(scores\u001B[38;5;241m.\u001B[39mshape, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mbool\u001B[39m)\n\u001B[0;32m    688\u001B[0m     \u001B[38;5;66;03m# Request a stable sort. Mergesort takes more memory (~40MB per\u001B[39;00m\n\u001B[0;32m    689\u001B[0m     \u001B[38;5;66;03m# megafeature on x86-64).\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:31\u001B[0m, in \u001B[0;36m_clean_nans\u001B[1;34m(scores)\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;124;03mFixes Issue #1240: NaNs can't be properly compared, so change them to the\u001B[39;00m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;124;03msmallest value of scores's dtype. -inf seems to be unreliable.\u001B[39;00m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;66;03m# XXX where should this function be called? fit? scoring functions\u001B[39;00m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;66;03m# themselves?\u001B[39;00m\n\u001B[1;32m---> 31\u001B[0m scores \u001B[38;5;241m=\u001B[39m \u001B[43mas_float_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mscores\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     32\u001B[0m scores[np\u001B[38;5;241m.\u001B[39misnan(scores)] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mfinfo(scores\u001B[38;5;241m.\u001B[39mdtype)\u001B[38;5;241m.\u001B[39mmin\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m scores\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:254\u001B[0m, in \u001B[0;36mas_float_array\u001B[1;34m(X, copy, force_all_finite)\u001B[0m\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    253\u001B[0m     return_dtype \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mfloat64\n\u001B[1;32m--> 254\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreturn_dtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: float() argument must be a string or a real number, not 'rv_continuous_frozen'"
     ]
    }
   ],
   "source": [
    "X_train_chi2 = X_train\n",
    "select_chi2 = SelectKBest(chi2, k = 30)\n",
    "select_chi2.fit_transform(X_train_chi2, y_train)\n",
    "features_b_chi = select_chi2.get_support(indices=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = RFE(estimator=Ridge(alpha=1.0), n_features_to_select=num_of_features)\n",
    "model.fit_transform(X_train, y_train)\n",
    "features_b_rfe = model.get_support(indices=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = SelectKBest(score_func=mutual_info_classif, k=num_of_features)\n",
    "model.fit_transform(X_train, y_train)\n",
    "features_b_mut = model.get_support(indices=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    SVC(),\n",
    "    RandomForestClassifier()\n",
    "]\n",
    "\n",
    "def get_score_for_classifier(classifier):\n",
    "    class_before = classifier\n",
    "    class_before.fit(X_train, y_train)\n",
    "    predict_before = class_before.predict(X_test)\n",
    "    score_before = accuracy_score(y_test, predict_before)\n",
    "    return score_before\n",
    "\n",
    "classifiers_values = [\n",
    "    get_score_for_classifier(i) for i in classifiers\n",
    "]\n",
    "features_values = []\n",
    "features_values.clear()\n",
    "features_values.append(features_v)\n",
    "features_values.append(features_w)\n",
    "features_values.append(features_f)\n",
    "features_values.append(features_b_chi)\n",
    "features_values.append(features_b_rfe)\n",
    "features_values.append(features_b_mut)\n",
    "def build_diff(feature_num):\n",
    "    print(f'Difference for {features_methods[feature_num]}')\n",
    "    for i, classifier in enumerate(classifiers):\n",
    "        classifier_name = classifier.__class__.__name__\n",
    "\n",
    "        score_before = classifiers_values[i]\n",
    "\n",
    "        class_after = classifier\n",
    "        class_after.fit(X_train[:, features_values[feature_num]], y_train)\n",
    "        predict_after = class_after.predict(X_test[:, features_values[feature_num]])\n",
    "        score_after = accuracy_score(y_test, predict_after)\n",
    "\n",
    "        print(f'{classifier_name} before: {score_before}')\n",
    "        print(f'{classifier_name} after: {score_after}')\n",
    "        print(f'{classifier_name} difference: {score_after - score_before} \\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_methods = [\n",
    "    'Встроенный',\n",
    "    'Оберточный',\n",
    "    'Фильтрующий',\n",
    "    'RFE',\n",
    "    'Фильтр с chi2',\n",
    "    'Фильтр с mutual info',\n",
    "]\n",
    "for i in range(len(features_methods)):\n",
    "    build_diff(i)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
