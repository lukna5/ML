{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Dense, LSTM\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "text = open('AdamsText.txt', 'r', encoding='utf-8').read()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def reformat(stroke):\n",
    "    stroke = stroke.lower()\n",
    "    stroke = re.sub(r'[ё]', 'е', stroke)\n",
    "    stroke = re.sub(r\"[^а-я\\.\\-\\s+]+\", \"\", stroke)\n",
    "    stroke = re.sub(r'\\s+', ' ', stroke)\n",
    "    stroke = re.sub(r'(\\.+\\s*)+', '. ', stroke)\n",
    "    stroke = re.sub(r'\\s*\\.+\\s*', '. ', stroke)\n",
    "    return stroke"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "text = reformat(text)\n",
    "chars_list = sorted(list(set(text)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '-', '.', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я']\n",
      "{' ': 0, '-': 1, '.': 2, 'а': 3, 'б': 4, 'в': 5, 'г': 6, 'д': 7, 'е': 8, 'ж': 9, 'з': 10, 'и': 11, 'й': 12, 'к': 13, 'л': 14, 'м': 15, 'н': 16, 'о': 17, 'п': 18, 'р': 19, 'с': 20, 'т': 21, 'у': 22, 'ф': 23, 'х': 24, 'ц': 25, 'ч': 26, 'ш': 27, 'щ': 28, 'ъ': 29, 'ы': 30, 'ь': 31, 'э': 32, 'ю': 33, 'я': 34}\n",
      "{0: ' ', 1: '-', 2: '.', 3: 'а', 4: 'б', 5: 'в', 6: 'г', 7: 'д', 8: 'е', 9: 'ж', 10: 'з', 11: 'и', 12: 'й', 13: 'к', 14: 'л', 15: 'м', 16: 'н', 17: 'о', 18: 'п', 19: 'р', 20: 'с', 21: 'т', 22: 'у', 23: 'ф', 24: 'х', 25: 'ц', 26: 'ч', 27: 'ш', 28: 'щ', 29: 'ъ', 30: 'ы', 31: 'ь', 32: 'э', 33: 'ю', 34: 'я'}\n"
     ]
    }
   ],
   "source": [
    "chars = dict((c, i) for i, c in enumerate(chars_list))\n",
    "indexes = dict((i, c) for i, c in enumerate(chars_list))\n",
    "print(chars_list)\n",
    "print(chars)\n",
    "print(indexes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['глава каждое', 'лава каждое ', 'ава каждое у', 'ва каждое ут', 'а каждое утр', ' каждое утро', 'каждое утро ', 'аждое утро т', 'ждое утро тр', 'дое утро тра']\n",
      "[' ', 'у', 'т', 'р', 'о', ' ', 'т', 'р', 'а', 'д']\n"
     ]
    }
   ],
   "source": [
    "seq_len = 12\n",
    "dataX = list(s[i:i + seq_len] for s in text.split('.') for i in range(len(s) - seq_len))\n",
    "dataY = list(s[seq_len + i] for s in text.split('.') for i in range(len(s) - seq_len))\n",
    "print(dataX[:10])\n",
    "print(dataY[:10])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Приведем данные к OneHot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "X = np.zeros((len(dataX), seq_len, len(chars)))\n",
    "Y = np.zeros((len(dataX), len(chars)))\n",
    "for i, s in enumerate(dataX):\n",
    "    for j, ch in enumerate(s):\n",
    "        X[i, j, chars[ch]] = 1\n",
    "    Y[i, chars[dataY[i]]] = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LSTM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "964/964 [==============================] - 44s 42ms/step - loss: 2.7945\n",
      "Epoch 2/30\n",
      "964/964 [==============================] - 45s 46ms/step - loss: 2.4131\n",
      "Epoch 3/30\n",
      "964/964 [==============================] - 41s 42ms/step - loss: 2.2531\n",
      "Epoch 4/30\n",
      "964/964 [==============================] - 38s 39ms/step - loss: 2.1232\n",
      "Epoch 5/30\n",
      "964/964 [==============================] - 37s 39ms/step - loss: 1.9982\n",
      "Epoch 6/30\n",
      "964/964 [==============================] - 36s 37ms/step - loss: 1.8750\n",
      "Epoch 7/30\n",
      "964/964 [==============================] - 36s 38ms/step - loss: 1.7398\n",
      "Epoch 8/30\n",
      "964/964 [==============================] - 41s 43ms/step - loss: 1.5936\n",
      "Epoch 9/30\n",
      "964/964 [==============================] - 44s 45ms/step - loss: 1.4298\n",
      "Epoch 10/30\n",
      "964/964 [==============================] - 36s 38ms/step - loss: 1.2546\n",
      "Epoch 11/30\n",
      "964/964 [==============================] - 47s 49ms/step - loss: 1.0778\n",
      "Epoch 12/30\n",
      "964/964 [==============================] - 41s 43ms/step - loss: 0.8969\n",
      "Epoch 13/30\n",
      "964/964 [==============================] - 36s 37ms/step - loss: 0.7298\n",
      "Epoch 14/30\n",
      "964/964 [==============================] - 36s 38ms/step - loss: 0.5780\n",
      "Epoch 15/30\n",
      "964/964 [==============================] - 45s 47ms/step - loss: 0.4465\n",
      "Epoch 16/30\n",
      "964/964 [==============================] - 36s 38ms/step - loss: 0.3452\n",
      "Epoch 17/30\n",
      "964/964 [==============================] - 37s 38ms/step - loss: 0.2725\n",
      "Epoch 18/30\n",
      "964/964 [==============================] - 35s 36ms/step - loss: 0.2204\n",
      "Epoch 19/30\n",
      "964/964 [==============================] - 35s 36ms/step - loss: 0.1888\n",
      "Epoch 20/30\n",
      "964/964 [==============================] - 36s 37ms/step - loss: 0.1649\n",
      "Epoch 21/30\n",
      "964/964 [==============================] - 36s 38ms/step - loss: 0.1564\n",
      "Epoch 22/30\n",
      "964/964 [==============================] - 38s 40ms/step - loss: 0.1457\n",
      "Epoch 23/30\n",
      "964/964 [==============================] - 35s 37ms/step - loss: 0.1358\n",
      "Epoch 24/30\n",
      "964/964 [==============================] - 43s 45ms/step - loss: 0.1244\n",
      "Epoch 25/30\n",
      "964/964 [==============================] - 43s 44ms/step - loss: 0.1252\n",
      "Epoch 26/30\n",
      "964/964 [==============================] - 48s 49ms/step - loss: 0.1262\n",
      "Epoch 27/30\n",
      "964/964 [==============================] - 37s 38ms/step - loss: 0.1165\n",
      "Epoch 28/30\n",
      "964/964 [==============================] - 41s 43ms/step - loss: 0.1161\n",
      "Epoch 29/30\n",
      "964/964 [==============================] - 40s 41ms/step - loss: 0.1176\n",
      "Epoch 30/30\n",
      "964/964 [==============================] - 38s 40ms/step - loss: 0.1074\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 256)               299008    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 35)                8995      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 308,003\n",
      "Trainable params: 308,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dense(Y.shape[1], activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "model.fit(X, Y, epochs=30)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start sentence :  кличем внеза\n",
      "Result of predict :  кличем внезапного восторга он спрыгнул с у \n",
      "\n",
      "Start sentence :   мебельные м\n",
      "Result of predict :   мебельные магазины громят воскликнул форд \n",
      "\n",
      "Start sentence :  где вы ее на\n",
      "Result of predict :  где вы ее нашли и как сюда переместили по- \n",
      "\n",
      "Start sentence :  е подробност\n",
      "Result of predict :  е подробности аварии не имеют значения пос \n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_tests = 4\n",
    "num_predict = 30\n",
    "\n",
    "for _ in range(num_tests):\n",
    "    cur_sentence = dataX[np.random.randint(len(dataX) - 1)]\n",
    "    sentence = cur_sentence\n",
    "    res = cur_sentence\n",
    "    appended = \"\"\n",
    "    for _ in range(num_predict):\n",
    "        cur_hot = np.zeros((1, seq_len, len(chars_list)))\n",
    "        for i, ch in enumerate(cur_sentence):\n",
    "            cur_hot[0, i, chars[ch]] = 1\n",
    "        predict = model.predict(cur_hot, verbose=0)\n",
    "        next_ch = indexes[np.argmax(predict)]\n",
    "        cur_sentence = cur_sentence[1:] + next_ch\n",
    "        appended += next_ch\n",
    "    print('Start sentence : ', sentence)\n",
    "    print('Result of predict : ', res + appended, '\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Готовим цепь"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "nexts = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "for s, c in zip(dataX, dataY):\n",
    "    nexts[s][c] += 1\n",
    "for sent in dataX:\n",
    "    sum_next = sum([v for v in nexts[sent].values()])\n",
    "    for next in nexts[sent]:\n",
    "        nexts[sent][next] /= sum_next"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Протестим"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start sentence :  его лучи лас\n",
      "Result of predict :  его лучи ласкали брикеты мороженого от чег \n",
      "\n",
      "Start sentence :  нь интересно\n",
      "Result of predict :  нь интересно заявил форд пододвинув к арту \n",
      "\n",
      "Start sentence :   субэфирный \n",
      "Result of predict :   субэфирный чуткомат \n",
      "\n",
      "Start sentence :  ловно это бы\n",
      "Result of predict :  ловно это был не чай а но в данном случае  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(num_tests):\n",
    "    cur_sentence = dataX[np.random.randint(len(dataX) - 1)]\n",
    "    sentence = cur_sentence\n",
    "    appended = \"\"\n",
    "    for _ in range(num_predict):\n",
    "        next_symbols = nexts[cur_sentence]\n",
    "        p = list(next_symbols.values())\n",
    "        if len(p) == 0:\n",
    "            break\n",
    "        next_symb = list(next_symbols.items())[np.random.choice(len(p), p=np.array(p))][0]\n",
    "        cur_sentence += next_symb\n",
    "        cur_sentence = cur_sentence[1:]\n",
    "        appended += next_symb\n",
    "    print('Start sentence : ', sentence)\n",
    "    print('Result of predict : ', sentence + appended, '\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
